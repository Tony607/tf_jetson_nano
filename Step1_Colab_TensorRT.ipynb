{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Step1_Colab_TensorRT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQK7KlhRBfnf",
        "colab_type": "text"
      },
      "source": [
        "# Step 1 : Convert Keras model into TensorRT model\n",
        "**For more detail, checkout [How to run Keras model on Jetson Nano](https://www.dlology.com/blog/how-to-run-keras-model-on-jetson-nano/) | DLology Blog**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63ULC43DRlKC",
        "colab_type": "text"
      },
      "source": [
        "Changing the runtime to Python2\n",
        "to get use of Tensorflow version to 1.14.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fitngHJnRsNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==1.14.0\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITUc4J7etACS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.contrib.tensorrt as trt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsZgX4XeuNkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download an image for prediction.\n",
        "\n",
        "!wget --quiet https://raw.githubusercontent.com/Tony607/tf_jetson_nano/master/data/elephant.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWygvIyctpeI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2 as Net\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Optional image to test model prediction.\n",
        "img_path = '/content/elephant.jpg'\n",
        "model_path = '/content/model'\n",
        "\n",
        "#os.makedirs(model_path, exist_ok=True)\n",
        "# Path to save the model h5 file.\n",
        "model_fname = os.path.join(model_path, 'model.h5')\n",
        "\n",
        "#os.makedirs(model_path, exist_ok=True)\n",
        "\n",
        "img_height = 224\n",
        "\n",
        "model = Net(weights='imagenet')\n",
        "\n",
        "\n",
        "# Load the image for prediction.\n",
        "img = image.load_img(img_path, target_size=(img_height, img_height))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "# decode the results into a list of tuples (class, description, probability)\n",
        "# (one such list for each sample in the batch)\n",
        "print('Predicted:', decode_predictions(preds, top=3)[0])\n",
        "# Predicted: [(u'n02504013', u'Indian_elephant', 0.82658225), (u'n01871265', u'tusker', 0.1122357), (u'n02504458', u'African_elephant', 0.061040461)]\n",
        "\n",
        "# Save the h5 file to path specified.\n",
        "model.save(model_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OY9k1o9iulZF",
        "colab_type": "text"
      },
      "source": [
        "### Benchmark Keras prediction speed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGqN3UXquW-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "times = []\n",
        "for i in range(20):\n",
        "    start_time = time.time()\n",
        "    preds = model.predict(x)\n",
        "    delta = (time.time() - start_time)\n",
        "    times.append(delta)\n",
        "mean_delta = np.array(times).mean()\n",
        "fps = 1/mean_delta\n",
        "print('average(sec):{},fps:{}'.format(mean_delta,fps))\n",
        "\n",
        "# Clear any previous session.\n",
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBsv7z2WukCz",
        "colab_type": "text"
      },
      "source": [
        "## Freeze graph, generate `.pb` file.\n",
        "Take a notes of the input and output nodes names printed in the output, we will need them when converting `TensorRT` graph and prediction.\n",
        "\n",
        "For Keras MobileNetV2, they are,\n",
        "```\n",
        "['input_1'] ['Logits/Softmax']\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-Jx1Yq0uejv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# force reset ipython namespaces\n",
        "%reset -f\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import graph_io\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "# Clear any previous session.\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "save_pb_dir = './model'\n",
        "model_fname = './model/model.h5'\n",
        "def freeze_graph(graph, session, output, save_pb_dir='.', save_pb_name='frozen_model.pb', save_pb_as_text=False):\n",
        "    with graph.as_default():\n",
        "        graphdef_inf = tf.graph_util.remove_training_nodes(graph.as_graph_def())\n",
        "        graphdef_frozen = tf.graph_util.convert_variables_to_constants(session, graphdef_inf, output)\n",
        "        graph_io.write_graph(graphdef_frozen, save_pb_dir, save_pb_name, as_text=save_pb_as_text)\n",
        "        return graphdef_frozen\n",
        "\n",
        "# This line must be executed before loading Keras model.\n",
        "tf.keras.backend.set_learning_phase(0) \n",
        "\n",
        "model = load_model(model_fname)\n",
        "\n",
        "session = tf.keras.backend.get_session()\n",
        "\n",
        "input_names = [t.op.name for t in model.inputs]\n",
        "output_names = [t.op.name for t in model.outputs]\n",
        "\n",
        "# Prints input and output nodes names, take notes of them.\n",
        "print(input_names, output_names)\n",
        "\n",
        "frozen_graph = freeze_graph(session.graph, session, [out.op.name for out in model.outputs], save_pb_dir=save_pb_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38l-D915vahb",
        "colab_type": "text"
      },
      "source": [
        "## Optimize with TensorRT\n",
        "Save the result as `.pb` file.\n",
        "\n",
        "*Notes: optimizing TensorRT graph can also be executed on Jetson Nano, but it is very slow.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9qanB3Du2i-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.contrib.tensorrt as trt\n",
        "\n",
        "trt_graph = trt.create_inference_graph(\n",
        "    input_graph_def=frozen_graph,\n",
        "    outputs=output_names,\n",
        "    max_batch_size=1,\n",
        "    max_workspace_size_bytes=1 << 25,\n",
        "    precision_mode='FP16',\n",
        "    minimum_segment_size=50\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azhh5OA2vI72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "graph_io.write_graph(trt_graph, \"/content/model/\",\n",
        "                     \"trt_graph.pb\", as_text=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLg8O3dfvOum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls model -alh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPVLp1FKvnSF",
        "colab_type": "text"
      },
      "source": [
        "### Download the tensorRT graph `.pb` file from colab to your local machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrHyjN_Cvk4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('./model/trt_graph.pb')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Hg6qDGIwmQn",
        "colab_type": "text"
      },
      "source": [
        "**Next step**: transfer the `trt_graph.pb` to your Jetson Nano, load it up and make predictions.\n",
        "\n",
        "\n",
        "`Step2_keras-jetson-ImageNet-predict.ipynb`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b6xtTKp_ve7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
